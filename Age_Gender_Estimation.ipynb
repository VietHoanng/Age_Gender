{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnjkimNmZXWm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYmsLa1FUdtA",
        "outputId": "09fe178e-acbe-49f6-a757-5e06af5429c9"
      },
      "outputs": [],
      "source": [
        "# Install OpenCV if not already installed\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJcab2ZHW5ft",
        "outputId": "a5a1279b-bc5e-4c97-e5c9-7694b6403271"
      },
      "outputs": [],
      "source": [
        "# Download model files from a reliable source (e.g., Google Drive or original repo)\n",
        "# Note: Replace these URLs with actual links if needed, as GitHub LFS may not serve files directly\n",
        "!wget -O opencv_face_detector.pbtxt https://raw.githubusercontent.com/smahesh29/Gender-and-Age-Detection/master/opencv_face_detector.pbtxt\n",
        "!wget -O opencv_face_detector_uint8.pb https://github.com/smahesh29/Gender-and-Age-Detection/raw/master/opencv_face_detector_uint8.pb\n",
        "!wget -O age_deploy.prototxt https://raw.githubusercontent.com/smahesh29/Gender-and-Age-Detection/master/age_deploy.prototxt\n",
        "!wget -O age_net.caffemodel https://github.com/smahesh29/Gender-and-Age-Detection/raw/master/age_net.caffemodel\n",
        "!wget -O gender_deploy.prototxt https://raw.githubusercontent.com/smahesh29/Gender-and-Age-Detection/master/gender_deploy.prototxt\n",
        "!wget -O gender_net.caffemodel https://github.com/smahesh29/Gender-and-Age-Detection/raw/master/gender_net.caffemodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhxC8mUFZs-Y"
      },
      "outputs": [],
      "source": [
        "# Function to highlight faces (adapted from original repo)\n",
        "def highlightFace(net, frame, conf_threshold=0.7):\n",
        "    frameOpencvDnn = frame.copy()\n",
        "    frameHeight = frameOpencvDnn.shape[0]\n",
        "    frameWidth = frameOpencvDnn.shape[1]\n",
        "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "    faceBoxes = []\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > conf_threshold:\n",
        "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
        "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
        "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
        "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
        "            faceBoxes.append([x1, y1, x2, y2])\n",
        "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight / 150)), 8)\n",
        "    return frameOpencvDnn, faceBoxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EoG55McZwzU"
      },
      "outputs": [],
      "source": [
        "# Load model files\n",
        "faceProto = \"opencv_face_detector.pbtxt\"\n",
        "faceModel = \"opencv_face_detector_uint8.pb\"\n",
        "ageProto = \"age_deploy.prototxt\"\n",
        "ageModel = \"age_net.caffemodel\"\n",
        "genderProto = \"gender_deploy.prototxt\"\n",
        "genderModel = \"gender_net.caffemodel\"\n",
        "\n",
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
        "genderList = ['Male', 'Female']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSWvIaDWZzbu"
      },
      "outputs": [],
      "source": [
        "# Initialize networks\n",
        "faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
        "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
        "genderNet = cv2.dnn.readNet(genderModel, genderProto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i97Lqd6pZ3AB"
      },
      "outputs": [],
      "source": [
        "# Function to process image\n",
        "def process_image(image_path):\n",
        "    frame = cv2.imread(image_path)\n",
        "    if frame is None:\n",
        "        print(\"Error: Could not load image.\")\n",
        "        return\n",
        "\n",
        "    resultImg, faceBoxes = highlightFace(faceNet, frame)\n",
        "    if not faceBoxes:\n",
        "        print(\"No face detected\")\n",
        "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    for faceBox in faceBoxes:\n",
        "        face = frame[max(0, faceBox[1] - 20):min(faceBox[3] + 20, frame.shape[0] - 1),\n",
        "                     max(0, faceBox[0] - 20):min(faceBox[2] + 20, frame.shape[1] - 1)]\n",
        "\n",
        "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "\n",
        "        # Gender prediction\n",
        "        genderNet.setInput(blob)\n",
        "        genderPreds = genderNet.forward()\n",
        "        gender = genderList[genderPreds[0].argmax()]\n",
        "\n",
        "        # Age prediction\n",
        "        ageNet.setInput(blob)\n",
        "        agePreds = ageNet.forward()\n",
        "        age = ageList[agePreds[0].argmax()]\n",
        "\n",
        "        # Draw label\n",
        "        label = f'{gender}, {age}'\n",
        "        cv2.putText(resultImg, label, (faceBox[0], faceBox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Display result\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(resultImg, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivLppvV-Z435"
      },
      "outputs": [],
      "source": [
        "# Webcam capture function (limited functionality in Colab)\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getActiveTrack().stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "        ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "kQzn6VtXZ7Lq",
        "outputId": "2d20bf4e-9ae1-4124-96f9-c2d68d5e2b85"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "print(\"Upload an image for age and gender detection:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print(f'Processing {fn}')\n",
        "    process_image(fn)\n",
        "\n",
        "# Optional: Webcam capture (uncomment to use, requires browser permission)\n",
        "# try:\n",
        "#     photo = take_photo()\n",
        "#     print('Processing webcam capture...')\n",
        "#     process_image(photo)\n",
        "# except Exception as err:\n",
        "#     print(f\"Webcam capture failed: {err}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
